{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlmaZohar.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "WQe5VDSMSfkB",
        "BmWuP156DGwg",
        "hfSTKtvMyhqU",
        "UR1rylYBWAnr"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHk3sYeyVEwu",
        "colab_type": "text"
      },
      "source": [
        "# Alma Zohar binary classification model using Transfer Learning \n",
        "\n",
        "Designed to detect if Alma or Zohar using Transfer learning of the VGG16, ResNet50 and InceptionV3 models\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQe5VDSMSfkB",
        "colab_type": "text"
      },
      "source": [
        "##Arrange our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6vQmcfjVwAR",
        "colab_type": "text"
      },
      "source": [
        "###Import training set from My Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9-7cArbjzbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3GX7aMOCI7n",
        "colab_type": "text"
      },
      "source": [
        "###Extract data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zvdJe_of5-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/ML/AlmaZohar.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp/AlmaZohar\")\n",
        "zip_ref.close()\n",
        "\n",
        "print(len(os.listdir('/tmp/AlmaZohar/Alma/')))\n",
        "print(len(os.listdir('/tmp/AlmaZohar/Zohar/')))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIXNqnANCQgV",
        "colab_type": "text"
      },
      "source": [
        "###Equalize category sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4I4LLyiavfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def even_data(cat1, cat2 ):\n",
        "  len1 = len(os.listdir(cat1))\n",
        "  len2 = len(os.listdir(cat2))\n",
        "  if  len1 > len2:\n",
        "    larger = cat1\n",
        "    smaller = cat2\n",
        "  else:\n",
        "    larger = cat2\n",
        "    smaller = cat1\n",
        "  \n",
        "  larger_len = len(os.listdir(larger))\n",
        "  smaller_len = len(os.listdir(smaller))\n",
        "  larger_image_list = os.listdir(larger)\n",
        "  larger_image_list = random.sample(larger_image_list, len(larger_image_list)) # Shuffle list\n",
        "  for idx, image in enumerate(larger_image_list):\n",
        "    image_path = larger + image\n",
        "    if os.path.getsize(image_path):\n",
        "      if idx < (larger_len - smaller_len):\n",
        "        os.remove(image_path)\n",
        "      else:\n",
        "        break\n",
        "    else:\n",
        "      print(image, \" is zero length, so ignoring\")\n",
        "\n",
        "\n",
        "\n",
        "even_data  ('/tmp/AlmaZohar/Alma/', '/tmp/AlmaZohar/Zohar/') \n",
        "print(len(os.listdir('/tmp/AlmaZohar/Alma/')))\n",
        "print(len(os.listdir('/tmp/AlmaZohar/Zohar/')))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJxDpuKqClYI",
        "colab_type": "text"
      },
      "source": [
        "### Arrange data for generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA6QcLDjfjso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "\n",
        "ALMA_SOURCE_DIR = \"/tmp/AlmaZohar/Alma/\"\n",
        "TRAINING_ALMA_DIR = \"/tmp/alma-vs-zohar/training/Alma/\"\n",
        "TESTING_ALMA_DIR = \"/tmp/alma-vs-zohar/testing/Alma/\"\n",
        "ZOHAR_SOURCE_DIR = \"/tmp/AlmaZohar/Zohar/\"\n",
        "TRAINING_ZOHAR_DIR = \"/tmp/alma-vs-zohar/training/Zohar/\"\n",
        "TESTING_ZOHAR_DIR = \"/tmp/alma-vs-zohar/testing/Zohar/\"\n",
        "\n",
        "\n",
        "Path(TRAINING_ALMA_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(TESTING_ALMA_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(TRAINING_ZOHAR_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(TESTING_ZOHAR_DIR).mkdir(parents=True, exist_ok=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV8wJu_XibSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from shutil import copyfile\n",
        "\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "  \n",
        "  source_image_list = os.listdir(SOURCE)\n",
        "  source_image_list = random.sample(source_image_list, len(source_image_list)) # Shuffle list\n",
        "  num_source_images = len(os.listdir(SOURCE))\n",
        "  split_num = round(num_source_images * SPLIT_SIZE)\n",
        "  for idx, image in enumerate(source_image_list):\n",
        "    image_path = SOURCE + image\n",
        "    if os.path.getsize(image_path):\n",
        "      if idx < split_num:\n",
        "        copyfile(image_path, TRAINING + image)\n",
        "      else:\n",
        "        copyfile(image_path, TESTING + image)\n",
        "    else:\n",
        "      print(image, \" is zero length, so ignoring\")\n",
        "\n",
        "#delete old files, if any\n",
        "!find \"/tmp/alma-vs-zohar/\" -type f -delete\n",
        "\n",
        "split_size = .7\n",
        "split_data(ALMA_SOURCE_DIR, TRAINING_ALMA_DIR, TESTING_ALMA_DIR, split_size)\n",
        "split_data(ZOHAR_SOURCE_DIR, TRAINING_ZOHAR_DIR, TESTING_ZOHAR_DIR, split_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnwaD9_81W",
        "colab_type": "text"
      },
      "source": [
        "Check the numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY_OMeAO3Piq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('total training Alma images:', len(os.listdir(TRAINING_ALMA_DIR)))\n",
        "print('total training Zohar images:', len(os.listdir(TRAINING_ZOHAR_DIR)))\n",
        "print('total validation Alma images:', len(os.listdir(TESTING_ALMA_DIR)))\n",
        "print('total validation Zohar images:', len(os.listdir(TESTING_ZOHAR_DIR)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11p6uMk2s08W",
        "colab_type": "text"
      },
      "source": [
        "###Create training and validation generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq6lk-LxtzzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "\n",
        "HEIGHT = 150\n",
        "WIDTH = 150\n",
        "\n",
        "TRAINING_DIR = '/tmp/alma-vs-zohar/training/'\n",
        "VALIDATION_DIR ='/tmp/alma-vs-zohar/testing'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                  preprocessing_function=preprocess_input,\n",
        "                                  rotation_range=40,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True,\n",
        "                                  fill_mode='nearest')\n",
        "\n",
        "\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "        \n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        TRAINING_DIR,  # This is the source directory for training images\n",
        "        target_size=(HEIGHT, WIDTH),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        VALIDATION_DIR,  # This is the source directory for training images\n",
        "        target_size=(HEIGHT, WIDTH),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "print( train_generator.class_indices)\n",
        "print( validation_generator.class_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPvCCFG4XwcJ",
        "colab_type": "text"
      },
      "source": [
        "## Build some models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmWuP156DGwg",
        "colab_type": "text"
      },
      "source": [
        "###Simple CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TRTtm4ADunI",
        "colab_type": "text"
      },
      "source": [
        "####Build and compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MvGgG-qDJ7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(HEIGHT, WIDTH, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "model.summary()\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.0001),\n",
        "              metrics=['acc'])\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA_3wRysDlHW",
        "colab_type": "text"
      },
      "source": [
        "####Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNYWQOFLDohQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 50\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                                      validation_data=validation_generator,\n",
        "                                       epochs=NUM_EPOCHS,\n",
        "                                      verbose=2)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfSTKtvMyhqU",
        "colab_type": "text"
      },
      "source": [
        "###VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlQg2QaAyljo",
        "colab_type": "text"
      },
      "source": [
        "####Fine tune on top of VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCkgutu_ysqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "base_model = VGG16(weights=None, \n",
        "                      include_top=False, \n",
        "                      input_shape=(HEIGHT, WIDTH, 3))\n",
        "\n",
        "\n",
        "for layer in base_model.layers: \n",
        "  layer.trainable = False\n",
        "base_model.summary()\n",
        "\n",
        "\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)\n",
        "\n",
        "    \n",
        "x = base_model.output\n",
        "x = layers.Flatten()(base_model.output) #last_output\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "x = layers.Dense (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDKpVOxvz_Ai",
        "colab_type": "text"
      },
      "source": [
        "####Train the model - VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn9g8X5n0CsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "\n",
        "model.compile( optimizer=RMSprop(lr=0.00001), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                                      validation_data=validation_generator,\n",
        "                                       epochs=NUM_EPOCHS,\n",
        "                                      verbose=2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBky9qyUJg9s",
        "colab_type": "text"
      },
      "source": [
        "####fine tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSBL-dbpJjxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train last ResNet block\n",
        "for layer in model.layers[:6]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[6:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                                      validation_data=validation_generator,\n",
        "                                       epochs=NUM_EPOCHS,\n",
        "                                      verbose=2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E3djGJeS0Ax",
        "colab_type": "text"
      },
      "source": [
        "###ResNet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_WzMJ6MUpGq",
        "colab_type": "text"
      },
      "source": [
        "####Fine tune on top of  Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFVyNjogX1o4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', \n",
        "                      include_top=False, \n",
        "                      input_shape=(HEIGHT, WIDTH, 3))\n",
        "\n",
        "\n",
        "# for layer in base_model.layers: \n",
        "#   layer.trainable = False\n",
        "# base_model.summary()\n",
        "\n",
        "x = base_model.output\n",
        "x = layers.Flatten()(base_model.output) #last_output\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "\n",
        "x = layers.Dense (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koEit6YztN_L",
        "colab_type": "text"
      },
      "source": [
        "#### Train our combiend model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIZvDY-0YAZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "model.compile( optimizer=RMSprop(lr=0.00001), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                                      validation_data=validation_generator,\n",
        "                                       epochs=NUM_EPOCHS,\n",
        "                                      verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_jQHcDLDVea",
        "colab_type": "text"
      },
      "source": [
        "####Fine tune if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9piXqubwDZIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "# for i, layer in enumerate(base_model.layers):\n",
        "#    print(i, layer.name)\n",
        "    \n",
        "\n",
        "    \n",
        "#Train last ResNet block\n",
        "# for layer in model.layers[:7]:\n",
        "#    layer.trainable = False\n",
        "# for layer in model.layers[7:]:\n",
        "#    layer.trainable = True\n",
        "    \n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                                      validation_data=validation_generator,\n",
        "                                       epochs=NUM_EPOCHS,\n",
        "                                      verbose=2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR1rylYBWAnr",
        "colab_type": "text"
      },
      "source": [
        "###Inception"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_GsZ66bWNju",
        "colab_type": "text"
      },
      "source": [
        "####Fine tune on top of Inception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luiWdaCddYLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "K.clear_session() #In order to keep layer names the same in every iteration\n",
        "\n",
        "\n",
        "pre_trained_model = InceptionV3(include_top=False,\n",
        "                               input_shape = (HEIGHT,WIDTH,3))\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make some layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers[:132]: #https://github.com/keras-team/keras/issues/9460#issuecomment-370736493\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HOr9dx-Wdlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "last_layer = pre_trained_model.get_layer(\"mixed5\")\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "x = layers.Flatten()(last_output) # pre_trained_model.output\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.4)(x)                  \n",
        "x = layers.Dense (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(inputs=pre_trained_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKSWTuVSYoWX",
        "colab_type": "text"
      },
      "source": [
        "####Train the combined model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsKVG0NCYlfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "      \n",
        "      \n",
        "      \n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=50,\n",
        "                              verbose=2,\n",
        "                              validation_data=validation_generator,\n",
        "                              callbacks = [callbacks])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fteZZ2UTDujB",
        "colab_type": "text"
      },
      "source": [
        "####Fine tune if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2MQ_C64DxGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(pre_trained_model.layers):\n",
        "   print(i, layer.name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV8gpAh_E9xY",
        "colab_type": "text"
      },
      "source": [
        "###Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX7kyP4nujwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6vSHzPR2ghH",
        "colab_type": "text"
      },
      "source": [
        "###Prediction\n",
        "\n",
        "Let's now take a look at actually running a prediction using the model. This code will allow you to choose 1 or more files from your file system, it will then upload them, and run them through the model, giving an indication of whether the object is a horse or a human."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86A4pJvaw354",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150,3))\n",
        "  x = image.img_to_array(img)\n",
        "  x = x/255\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=100)\n",
        "  print(classes)\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a Zohar\")\n",
        "  else:\n",
        "    print(fn + \" is a Alma\")\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}