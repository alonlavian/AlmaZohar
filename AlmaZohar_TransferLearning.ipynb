{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlmaZohar.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "rHk3sYeyVEwu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Alma Zohar binary classification model\n",
        "\n",
        "Designed to detect if Alma or Zohar using Transfer learning of the ResNet50 model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "D6vQmcfjVwAR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import training set from My Drive"
      ]
    },
    {
      "metadata": {
        "id": "E9-7cArbjzbM",
        "colab_type": "code",
        "outputId": "21d20044-0304-4b68-f568-acb82982c5e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "import os \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "\n",
        "# Directory with our training Zohar pictures\n",
        "train_Zohar_dir = os.path.join('/content/drive/My Drive/ML/AlmaZohar/Training/Zohar')\n",
        "\n",
        "# Directory with our training Alma pictures\n",
        "train_Alma_dir = os.path.join('/content/drive/My Drive/ML/AlmaZohar/Training/Alma')\n",
        "\n",
        "# Directory with our validation Zohar pictures\n",
        "val_Zohar_dir = os.path.join('/content/drive/My Drive/ML/AlmaZohar/Validation/Zohar')\n",
        "\n",
        "# Directory with our validation Alma pictures\n",
        "val_Alma_dir = os.path.join('/content/drive/My Drive/ML/AlmaZohar/Validation/Alma')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tvgnwaD9_81W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check that there are no duplicate images in training and vaslidation set"
      ]
    },
    {
      "metadata": {
        "id": "kY_OMeAO3Piq",
        "colab_type": "code",
        "outputId": "cf8cc201-7ef5-4ec5-ad68-34f9d3609b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "print('total training Alma images:', len(os.listdir(train_Alma_dir)))\n",
        "print('total training Zohar images:', len(os.listdir(train_Zohar_dir)))\n",
        "\n",
        "print('total validation Alma images:', len(os.listdir(val_Alma_dir)))\n",
        "print('total validation Zohar images:', len(os.listdir(val_Zohar_dir)))\n",
        "\n",
        "\n",
        "!diff -srq '/content/drive/My Drive/ML/AlmaZohar/Training/Alma' '/content/drive/My Drive/ML/AlmaZohar/Validation/Alma' | grep identical\n",
        "!diff -srq '/content/drive/My Drive/ML/AlmaZohar/Training/Zohar' '/content/drive/My Drive/ML/AlmaZohar/Validation/Zohar' | grep identical"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training Alma images: 44\n",
            "total training Zohar images: 50\n",
            "total validation Alma images: 10\n",
            "total validation Zohar images: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LPvCCFG4XwcJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer learning with ResNet50"
      ]
    },
    {
      "metadata": {
        "id": "nFVyNjogX1o4",
        "colab_type": "code",
        "outputId": "2afa45c7-5483-4789-b6ae-c8727c5ff7fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6528
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "HEIGHT = 300\n",
        "WIDTH = 300\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', \n",
        "                      include_top=False, \n",
        "                      input_shape=(HEIGHT, WIDTH, 3))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    for fc in fc_layers:\n",
        "        # New FC layer, random init\n",
        "        x = Dense(fc, activation='relu')(x) \n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    # New softmax layer\n",
        "    predictions = Dense(1, activation='sigmoid')(x) \n",
        "    \n",
        "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return finetune_model\n",
        "\n",
        "class_list = [\"Alma\", \"Zohar\"]\n",
        "FC_LAYERS = [512]\n",
        "dropout = 0.1\n",
        "\n",
        "finetune_model = build_finetune_model(base_model, \n",
        "                                      dropout=dropout, \n",
        "                                      fc_layers=FC_LAYERS, \n",
        "                                      num_classes=len(class_list))\n",
        "\n",
        "\n",
        "\n",
        "# Check the trainable status of the individual layers\n",
        "# for layer in finetune_model.layers:\n",
        "#     print(layer, layer.trainable)\n",
        "\n",
        "finetune_model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 300, 300, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 306, 306, 3)  0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 150, 150, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalizationV1) (None, 150, 150, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 150, 150, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 152, 152, 64) 0           activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 75, 75, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 75, 75, 64)   4160        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 75, 75, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 75, 75, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 75, 75, 64)   36928       activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 75, 75, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 75, 75, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 75, 75, 256)  16640       activation_296[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 75, 75, 256)  16640       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 75, 75, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 75, 75, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_96 (Add)                    (None, 75, 75, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 75, 75, 256)  0           add_96[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 75, 75, 64)   16448       activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 75, 75, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 75, 75, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 75, 75, 64)   36928       activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 75, 75, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 75, 75, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 75, 75, 256)  16640       activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 75, 75, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_97 (Add)                    (None, 75, 75, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 75, 75, 256)  0           add_97[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 75, 75, 64)   16448       activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 75, 75, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 75, 75, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 75, 75, 64)   36928       activation_301[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 75, 75, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 75, 75, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 75, 75, 256)  16640       activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 75, 75, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_98 (Add)                    (None, 75, 75, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 75, 75, 256)  0           add_98[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 38, 38, 128)  32896       activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 38, 38, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 38, 38, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 38, 38, 128)  147584      activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 38, 38, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 38, 38, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 38, 38, 512)  66048       activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 38, 38, 512)  131584      activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 38, 38, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 38, 38, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_99 (Add)                    (None, 38, 38, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 38, 38, 512)  0           add_99[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 38, 38, 128)  65664       activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 38, 38, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 38, 38, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 38, 38, 128)  147584      activation_307[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 38, 38, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 38, 38, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 38, 38, 512)  66048       activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 38, 38, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_100 (Add)                   (None, 38, 38, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 38, 38, 512)  0           add_100[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 38, 38, 128)  65664       activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 38, 38, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 38, 38, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 38, 38, 128)  147584      activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 38, 38, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 38, 38, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 38, 38, 512)  66048       activation_311[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 38, 38, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_101 (Add)                   (None, 38, 38, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 38, 38, 512)  0           add_101[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 38, 38, 128)  65664       activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 38, 38, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 38, 38, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 38, 38, 128)  147584      activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 38, 38, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 38, 38, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 38, 38, 512)  66048       activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 38, 38, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_102 (Add)                   (None, 38, 38, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 38, 38, 512)  0           add_102[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 19, 19, 256)  131328      activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 19, 19, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 19, 19, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 19, 19, 256)  590080      activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 19, 19, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 19, 19, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 19, 19, 1024) 263168      activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 19, 19, 1024) 525312      activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 19, 19, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 19, 19, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_103 (Add)                   (None, 19, 19, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 19, 19, 1024) 0           add_103[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 19, 19, 256)  262400      activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 19, 19, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 19, 19, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 19, 19, 256)  590080      activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 19, 19, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 19, 19, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 19, 19, 1024) 263168      activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 19, 19, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_104 (Add)                   (None, 19, 19, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 19, 19, 1024) 0           add_104[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 19, 19, 256)  262400      activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 19, 19, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 19, 19, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 19, 19, 256)  590080      activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 19, 19, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 19, 19, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 19, 19, 1024) 263168      activation_323[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 19, 19, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_105 (Add)                   (None, 19, 19, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 19, 19, 1024) 0           add_105[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 19, 19, 256)  262400      activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 19, 19, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 19, 19, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 19, 19, 256)  590080      activation_325[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 19, 19, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 19, 19, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 19, 19, 1024) 263168      activation_326[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 19, 19, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_106 (Add)                   (None, 19, 19, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 19, 19, 1024) 0           add_106[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 19, 19, 256)  262400      activation_327[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 19, 19, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 19, 19, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 19, 19, 256)  590080      activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 19, 19, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 19, 19, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 19, 19, 1024) 263168      activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 19, 19, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_107 (Add)                   (None, 19, 19, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_327[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 19, 19, 1024) 0           add_107[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 19, 19, 256)  262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 19, 19, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 19, 19, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 19, 19, 256)  590080      activation_331[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 19, 19, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 19, 19, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 19, 19, 1024) 263168      activation_332[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 19, 19, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_108 (Add)                   (None, 19, 19, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 19, 19, 1024) 0           add_108[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 10, 10, 512)  524800      activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 10, 10, 512)  2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 10, 10, 512)  0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 10, 10, 512)  2359808     activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 10, 10, 512)  2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 10, 10, 512)  0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 10, 10, 2048) 1050624     activation_335[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 10, 10, 2048) 2099200     activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 10, 10, 2048) 8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 10, 10, 2048) 8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_109 (Add)                   (None, 10, 10, 2048) 0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 10, 10, 2048) 0           add_109[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 10, 10, 512)  1049088     activation_336[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 10, 10, 512)  2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 10, 10, 512)  0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 10, 10, 512)  2359808     activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 10, 10, 512)  2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 10, 10, 512)  0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 10, 10, 2048) 1050624     activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 10, 10, 2048) 8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_110 (Add)                   (None, 10, 10, 2048) 0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_336[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 10, 10, 2048) 0           add_110[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 10, 10, 512)  1049088     activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 10, 10, 512)  2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 10, 10, 512)  0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 10, 10, 512)  2359808     activation_340[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 10, 10, 512)  2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, 10, 10, 512)  0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 10, 10, 2048) 1050624     activation_341[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 10, 10, 2048) 8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_111 (Add)                   (None, 10, 10, 2048) 0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, 10, 10, 2048) 0           add_111[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 204800)       0           activation_342[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 512)          104858112   flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 512)          0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 1)            513         dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 128,446,337\n",
            "Trainable params: 104,858,625\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "11p6uMk2s08W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generate our small training set"
      ]
    },
    {
      "metadata": {
        "id": "tq6lk-LxtzzM",
        "colab_type": "code",
        "outputId": "74c2e527-f678-4fda-fb7b-2d20c6ecccf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1/255,\n",
        "                                  preprocessing_function=preprocess_input,\n",
        "                                  rotation_range=90,\n",
        "#                                   horizontal_flip=True,\n",
        "#                                   vertical_flip=True,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2) # zoom in or out in images)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255,\n",
        "                                  preprocessing_function=preprocess_input,\n",
        "                                  rotation_range=90,\n",
        "#                                   horizontal_flip=True,\n",
        "#                                   vertical_flip=True,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2) # zoom in or out in images)\n",
        "        \n",
        "        \n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/ML/AlmaZohar/Training/',  # This is the source directory for training images\n",
        "        target_size=(300, 300),  # All images will be resized to 150x150\n",
        "        batch_size=100,\n",
        "        class_mode='binary')\n",
        "\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/ML/AlmaZohar/Validation/',  # This is the source directory for training images\n",
        "        target_size=(300, 300),  # All images will be resized to 150x150\n",
        "        batch_size=10,\n",
        "        class_mode='binary')\n",
        "\n",
        "print( train_generator.class_indices)\n",
        "print( validation_generator.class_indices)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 94 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n",
            "{'Alma': 0, 'Zohar': 1}\n",
            "{'Alma': 0, 'Zohar': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "koEit6YztN_L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train our combiend model"
      ]
    },
    {
      "metadata": {
        "id": "VIZvDY-0YAZ6",
        "colab_type": "code",
        "outputId": "27734bf5-c721-435e-e061-8ece2893ca97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "\n",
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 100\n",
        "num_train_images = 94\n",
        "\n",
        "adam = Adam(lr=0.00001)\n",
        "finetune_model.compile(adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# filepath=\"/tmp/\" + \"ResNet50\" + \"_model_weights.h5\"\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max')\n",
        "# callbacks_list = [checkpoint]\n",
        "\n",
        "history = finetune_model.fit_generator(train_generator,\n",
        "                                       validation_data=validation_generator,\n",
        "                                        validation_steps=2,\n",
        "                                       epochs=NUM_EPOCHS,\n",
        "                                       workers=8, \n",
        "                                       steps_per_epoch=1, \n",
        "                                       shuffle=True)\n",
        "#                                        callbacks=callbacks_list)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 6s 3s/step - loss: 1.2558 - acc: 0.5000\n",
            "1/1 [==============================] - 11s 11s/step - loss: 0.0962 - acc: 0.9787 - val_loss: 1.2558 - val_acc: 0.5000\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 5s 2s/step - loss: 0.7034 - acc: 0.6000\n",
            "1/1 [==============================] - 18s 18s/step - loss: 0.6141 - acc: 0.7553 - val_loss: 0.7034 - val_acc: 0.6000\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 5s 2s/step - loss: 0.8288 - acc: 0.5000\n",
            "1/1 [==============================] - 19s 19s/step - loss: 0.0419 - acc: 0.9894 - val_loss: 0.8288 - val_acc: 0.5000\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 4s 2s/step - loss: 0.7627 - acc: 0.5000\n",
            "1/1 [==============================] - 19s 19s/step - loss: 0.3324 - acc: 0.8511 - val_loss: 0.7627 - val_acc: 0.5000\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 6s 3s/step - loss: 0.6821 - acc: 0.5500\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.1930 - acc: 0.8830 - val_loss: 0.6821 - val_acc: 0.5500\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 5s 2s/step - loss: 0.8921 - acc: 0.5000\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.0462 - acc: 0.9894 - val_loss: 0.8921 - val_acc: 0.5000\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 5s 2s/step - loss: 1.1255 - acc: 0.5000\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.0570 - acc: 0.9894 - val_loss: 1.1255 - val_acc: 0.5000\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 5s 2s/step - loss: 1.1946 - acc: 0.5000\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.1527 - acc: 0.9255 - val_loss: 1.1946 - val_acc: 0.5000\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 5s 2s/step - loss: 1.1433 - acc: 0.5000\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.1458 - acc: 0.9574 - val_loss: 1.1433 - val_acc: 0.5000\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 5s 2s/step - loss: 0.9584 - acc: 0.5000\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.0706 - acc: 0.9681 - val_loss: 0.9584 - val_acc: 0.5000\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 4s 2s/step - loss: 0.8181 - acc: 0.5000\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.8181 - val_acc: 0.5000\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 5s 2s/step - loss: 0.7602 - acc: 0.5000\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.7602 - val_acc: 0.5000\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 5s 2s/step - loss: 0.6804 - acc: 0.5500\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.6804 - val_acc: 0.5500\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.6671 - acc: 0.6000\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.6671 - val_acc: 0.6000\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 5s 2s/step - loss: 0.6796 - acc: 0.6000\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0405 - acc: 0.9894 - val_loss: 0.6796 - val_acc: 0.6000\n",
            "Epoch 16/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8_cDgo_Nhi7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "b016a3dc-5180-4202-c73f-953eb28d8660"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Plot the training and validation loss + accuracy\n",
        "def plot_training(history):\n",
        "    acc = history.history['acc']\n",
        "    loss = history.history['loss']\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    \n",
        "    plt.figure(figsize=(20, 8))\n",
        "#     plt.figure(figsize=20.)\n",
        "    plt.grid(False)\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, acc, 'r.')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, loss, 'r.')\n",
        "    plt.title('Training and validation loss')\n",
        "    \n",
        "    plt.show()\n",
        "    plt.savefig('acc_vs_epochs.png')\n",
        "    \n",
        "plot_training(history)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIUAAAHhCAYAAADwEQ5GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTJBQCAAAAGCChEIAAAAAE/Q/vnG0FLTKGeEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "o6vSHzPR2ghH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Running the Model\n",
        "\n",
        "Let's now take a look at actually running a prediction using the model. This code will allow you to choose 1 or more files from your file system, it will then upload them, and run them through the model, giving an indication of whether the object is a horse or a human."
      ]
    },
    {
      "metadata": {
        "id": "86A4pJvaw354",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(300, 300))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = finetune_model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a Zohar\")\n",
        "  else:\n",
        "    print(fn + \" is a Alma\")\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-8EHQyWGDvWz"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizing Intermediate Representations\n",
        "\n",
        "To get a feel for what kind of features our convnet has learned, one fun thing to do is to visualize how an input gets transformed as it goes through the convnet.\n",
        "\n",
        "Let's pick a random image from the training set, and then generate a figure where each row is the output of a layer, and each image in the row is a specific filter in that output feature map. Rerun this cell to generate intermediate representations for a variety of training images."
      ]
    },
    {
      "metadata": {
        "id": "8R0GiDUBxKjK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# !pip install -U --force-reinstall matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers,models\n",
        "\n",
        "\n",
        "# Let's define a new Model that will take an image as input, and will output\n",
        "# intermediate representations for all layers in the previous model after\n",
        "# the first.\n",
        "successive_outputs = [layer.output for layer in finetune_model.layers[1:]]\n",
        "#visualization_model = Model(img_input, successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(inputs = finetune_model.input, outputs = successive_outputs)\n",
        "# Let's prepare a random input image from the training set.\n",
        "Alma_img_files = [os.path.join(train_Alma_dir, f) for f in train_Alma_names]\n",
        "Zohar_img_files = [os.path.join(train_Zohar_dir, f) for f in train_Zohar_names]\n",
        "img_path = random.choice(Alma_img_files + Zohar_img_files)\n",
        "\n",
        "img = load_img('/content/drive/My Drive/Training/Alma/IMG_20140304_065535.jpg', target_size=(300, 300))  # this is a PIL image\n",
        "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
        "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /= 255\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in finetune_model.layers]\n",
        "\n",
        "# Now let's display our representations\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  if len(feature_map.shape) == 4:\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
        "#     print (n_features)\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = feature_map.shape[1]\n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    for i in range(n_features):\n",
        "      # Postprocess the feature to make it visually palatable\n",
        "      x = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std()\n",
        "      x *= 64\n",
        "      x += 128\n",
        "      x = np.clip(x, 0, 255).astype('uint8')\n",
        "      # We'll tile each filter into this big horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "    # Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale * n_features, scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}